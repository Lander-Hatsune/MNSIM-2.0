{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# layer.py对照\n",
    "检查quantize和layers能否保证在各个模式下完全一致，包括structure_forward。、\n",
    "\n",
    "首先，利用暂存的Lenet权重，提取第一层并保存，并记录相关信息，同时随机生成一组input作为简单的测试\n",
    "LeNet的测试已经通过，在三种不同的模式下都能保证一致\n",
    "\n",
    "接着测试VGG8的第二个卷积层，这样可以保证存在被划分的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "weights = torch.load(\"../zoo/cifar10_vgg8_params.pth\")\n",
    "# print(weights.keys())\n",
    "layer = dict()\n",
    "for name, params in weights.items():\n",
    "    if name.startswith(\"layer_list.3\"):\n",
    "        layer[name[len(\"layer_list.3.\"):]] = params\n",
    "# save layer1\n",
    "torch.save(layer, \"../zoo/cifar10_test_layer.pth\")\n",
    "# print(layer[\"bit_scale_list\"])\n",
    "# save input\n",
    "input = torch.clamp(torch.randn(1, 128, 4, 4), 0, 1) * \\\n",
    "    (255 * layer[\"bit_scale_list\"][0, 1].item())\n",
    "torch.save(input, \"../zoo/cifar10_test_input.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import MNSIM.Interface.quantize as quantize\n",
    "from MNSIM.Interface.quantize import QuantizeLayer\n",
    "hardware_config = {\n",
    "    \"xbar_size\": 512,\n",
    "    \"input_bit\": 2,\n",
    "    \"weight_bit\": 1,\n",
    "    \"quantize_bit\": 10,\n",
    "}\n",
    "layer_config = {\n",
    "    \"type\": \"conv\",\n",
    "    \"in_channels\": 128,\n",
    "    \"out_channels\": 128,\n",
    "    \"kernel_size\": 3,\n",
    "}\n",
    "quantize_config = {\n",
    "    \"weight_bit\": 9,\n",
    "    \"activation_bit\": 9,\n",
    "    \"point_shift\": -2,\n",
    "}\n",
    "layer = QuantizeLayer(hardware_config, layer_config, quantize_config)\n",
    "layer.load_state_dict(torch.load(\"../zoo/cifar10_test_layer.pth\"))\n",
    "input = torch.load(\"../zoo/cifar10_test_input.pth\")\n",
    "# forward\n",
    "quantize.last_activation_scale = 4.8407 * 1e-3\n",
    "quantize.last_activation_bit = 9\n",
    "layer.eval()\n",
    "output = layer.forward(input, method=\"SINGLE_FIX_TEST\")\n",
    "print(output)\n",
    "torch.save(output, \"quantize.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from MNSIM.Interface.layer import BaseWeightLayer\n",
    "layer_ini = {\n",
    "    \"layer\": {\n",
    "        \"in_channels\": 128,\n",
    "        \"out_channels\": 128,\n",
    "        \"kernel_size\": 3,\n",
    "    },\n",
    "    \"quantize\": {\n",
    "        \"input\": 9,\n",
    "        \"weight\": 9,\n",
    "        \"output\": 9,\n",
    "    },\n",
    "    \"hardware\": {\n",
    "        \"xbar_row\": 512,\n",
    "        \"cell_bit\": 1,\n",
    "        \"dac_bit\": 2,\n",
    "        \"adc_bit\": 10,\n",
    "        \"point_shift\": -2,\n",
    "    }\n",
    "}\n",
    "layer = BaseWeightLayer.get_class_(\"conv\")(layer_ini)\n",
    "layer.load_state_dict(torch.load(\"../zoo/cifar10_test_layer.pth\"), strict=False)\n",
    "input = torch.load(\"../zoo/cifar10_test_input.pth\")\n",
    "# forward\n",
    "layer.eval()\n",
    "input_config = [torch.FloatTensor([9, 4.8407 * 1e-3])]\n",
    "output = layer.forward(input, method=\"SINGLE_FIX_TEST\", input_config=input_config)\n",
    "print(output)\n",
    "torch.save(output, \"layer.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.load(\"layer.pth\")\n",
    "b = torch.load(\"quantize.pth\")\n",
    "print(torch.max(a-b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检查model是否正确，并和之前的结果做对照"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "input = torch.clamp(torch.randn(1, 3, 32, 32), 0, 1)\n",
    "torch.save(input, \"model_input.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from MNSIM.Interface.dataset import ClassificationBaseDataset\n",
    "from MNSIM.Interface.model import BaseModel\n",
    "\n",
    "dataset_ini = {\n",
    "    \"TRAIN_BATCH_SIZE\": 128,\n",
    "    \"TRAIN_NUM_WORKERS\": 4,\n",
    "    \"TEST_BATCH_SIZE\": 100,\n",
    "    \"TEST_NUM_WORKERS\": 4,\n",
    "}\n",
    "model_config_path = \"lenet.yaml\"\n",
    "dataset = ClassificationBaseDataset.get_class_(\"cifar10\")(dataset_ini)\n",
    "model = BaseModel.get_class_(\"yaml\")(model_config_path, dataset.get_dataset_info())\n",
    "model.load_change_weights(torch.load(\"../zoo/cifar10_lenet_params.pth\"))\n",
    "# input\n",
    "input = torch.load(\"model_input.pth\")\n",
    "model.eval()\n",
    "output = model.forward(input, method=\"SINGLE_FIX_TEST\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)\n",
    "print(output)\n",
    "torch.save(output, \"model_output.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from MNSIM.Interface.network import get_net\n",
    "net = get_net(cate=\"lenet\", num_classes=10)\n",
    "net.load_state_dict(torch.load(\"../zoo/cifar10_lenet_params.pth\"))\n",
    "# input\n",
    "input = torch.load(\"model_input.pth\")\n",
    "net.eval()\n",
    "output = net.forward(input, method=\"SINGLE_FIX_TEST\")\n",
    "print(output)\n",
    "torch.save(output, \"net_output.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.load(\"model_output.pth\")\n",
    "b = torch.load(\"net_output.pth\")\n",
    "print(a)\n",
    "print(b)\n",
    "print(torch.max(a-b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "for i in range(17):\n",
    "    a = torch.load(f\"modle_list_{i}.pth\")\n",
    "    b = torch.load(f\"net_list_{i}.pth\")\n",
    "    print(torch.max(torch.abs(a-b)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "336c25dfa027737acb76905ce3eb6d17346417a81c7e61a9cda13b7f69491512"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mnsim')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
